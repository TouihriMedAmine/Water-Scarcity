{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11418965,"sourceType":"datasetVersion","datasetId":7151536}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\n\n# Source folder with all images\nsource_folder = '/kaggle/input/water-data/images'\n\n# Destination folder where weâ€™ll store only the lake images\ndestination_folder = '/kaggle/working/harbor_data'\n\n# Create destination folder if it doesn't exist\nos.makedirs(destination_folder, exist_ok=True)\n\n# Loop through all files in the source folder\nfor filename in os.listdir(source_folder):\n    if filename.lower().startswith('harbor') and filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n        source_path = os.path.join(source_folder, filename)\n        destination_path = os.path.join(destination_folder, filename)\n        shutil.copy(source_path, destination_path)\n\nprint(f\"âœ… All lake images have been copied to: {destination_folder}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T00:29:05.085105Z","iopub.execute_input":"2025-04-28T00:29:05.085388Z","execution_failed":"2025-04-28T00:29:07.192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\n\n# Folder with lake images\nlake_folder = '/kaggle/working/harbor_data'\n\n# Target image size\nimg_size = (128, 128)\n\n# Lists to hold the images\nlake_images_gray = []\n\n# Loop over all lake images\nfor filename in os.listdir(lake_folder):\n    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n        img_path = os.path.join(lake_folder, filename)\n        \n        # Load image in grayscale\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        \n        # Resize to uniform shape\n        img = cv2.resize(img, img_size)\n        \n        # Normalize pixel values to range [0, 1]\n        img = img / 255.0\n        \n        # Add to list\n        lake_images_gray.append(img)\n\n# Convert to NumPy array and expand dims to add channel (needed for CNN/U-Net)\nX_gray = np.array(lake_images_gray)\nX_gray = np.expand_dims(X_gray, axis=-1)  # shape: (num_images, 128, 128, 1)\n\nprint(\"âœ… Preprocessing complete!\")\nprint(\"Shape of preprocessed data:\", X_gray.shape)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-28T00:29:07.193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\n\n# Paths\nlake_images_folder = '/kaggle/working/harbor_data'\ngenerated_masks_folder = '/kaggle/working/generated_masks'\nimg_size = (128, 128)\n\n# Create a folder to save generated masks\nos.makedirs(generated_masks_folder, exist_ok=True)\n\n# Loop through all lake images\nfor filename in os.listdir(lake_images_folder):\n    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n        img_path = os.path.join(lake_images_folder, filename)\n        \n        # Load the image in grayscale\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        \n        # Resize to uniform size\n        img = cv2.resize(img, img_size)\n        \n        # Thresholding: Water is assumed to have low intensity (darker pixels)\n        # We use a threshold value (e.g., 100), but this may need adjustment based on the dataset\n        _, mask = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)\n        \n        # Normalize the mask to be between 0 and 1 (for consistency with model input)\n        mask = mask / 255.0\n        \n        # Save the generated mask\n        mask_path = os.path.join(generated_masks_folder, filename)\n        cv2.imwrite(mask_path, (mask * 255).astype(np.uint8))  # save as 0 or 255 mask image\n\nprint(\"âœ… Masks have been generated and saved to:\", generated_masks_folder)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-28T00:29:07.193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\n\n# Folder with the lake images (preprocessed) and corresponding masks\nlake_folder = '/kaggle/working/harbor_data'\nmask_folder = '/kaggle/working/generated_masks'\n\n# Target image size\nimg_size = (128, 128)\n\n# Lists to hold the processed images\nlake_images_bw = []\nlake_images_intensity = []\n\n# Function to classify intensity\ndef classify_intensity(gray_image):\n    # Define intensity thresholds for low, medium, and high\n    low_threshold = 0.33\n    medium_threshold = 0.66\n    \n    # Normalize the image to range [0, 1]\n    normalized_image = gray_image / 255.0\n    \n    # Classify each pixel intensity into low (0), medium (1), or high (2)\n    intensity_map = np.digitize(normalized_image, bins=[low_threshold, medium_threshold])\n    \n    return intensity_map\n\n# Loop over all lake images\nfor filename in os.listdir(lake_folder):\n    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n        img_path = os.path.join(lake_folder, filename)\n        \n        # Load the image in grayscale (black and white)\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        \n        # Resize to uniform shape\n        img = cv2.resize(img, img_size)\n        \n        # Load corresponding mask (assuming masks are named the same as images)\n        mask_path = os.path.join(mask_folder, filename)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        mask = cv2.resize(mask, img_size)  # Resize mask to match image dimensions\n        \n        # Normalize the mask (optional, depending on mask format)\n        mask = mask / 255.0  # Mask values will be 0 (land) or 1 (water)\n        \n        # Apply mask: Set land areas (where mask is 0) to 0 in the image\n        img_masked = img * mask\n        \n        # Normalize the masked image to range [0, 1]\n        img_masked = img_masked / 255.0\n        \n        # Add the processed grayscale image (water areas only) to list\n        lake_images_bw.append(img_masked)\n        \n        # Classify the intensity for the water areas\n        intensity_map = classify_intensity(img_masked)\n        \n        # Add the intensity map to the list\n        lake_images_intensity.append(intensity_map)\n\n# Convert to NumPy arrays\nX_bw = np.array(lake_images_bw)  # shape: (num_images, 128, 128)\nX_intensity = np.array(lake_images_intensity)  # shape: (num_images, 128, 128)\n\n# Expanding dimensions to add the channel for CNN/U-Net (if needed)\nX_bw = np.expand_dims(X_bw, axis=-1)  # shape: (num_images, 128, 128, 1)\nX_intensity = np.expand_dims(X_intensity, axis=-1)  # shape: (num_images, 128, 128, 1)\n\n# Print output shapes\nprint(\"âœ… Preprocessing complete!\")\nprint(\"Shape of grayscale images:\", X_bw.shape)\nprint(\"Shape of intensity mapped images:\", X_intensity.shape)\n\n# Optional: Visualize some of the images to confirm\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 5))\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    plt.imshow(X_bw[i].reshape(img_size), cmap='gray')\n    plt.title(f\"Intensity Map: {np.unique(X_intensity[i])}\")\n    plt.axis('off')\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-28T00:29:07.193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\n\n# Folder with lake images\nlake_folder = '/kaggle/working/harbor_data'\n\n# Folder with masks\nmask_folder = '/kaggle/working/generated_masks'\n\n# Target image size\nimg_size = (128, 128)\n\n# Function to load images and preprocess\ndef load_images_and_masks(lake_folder, mask_folder, img_size):\n    images = []\n    masks = []\n    \n    for filename in os.listdir(lake_folder):\n        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n            img_path = os.path.join(lake_folder, filename)\n            mask_path = os.path.join(mask_folder, filename)\n\n            # Load the image\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, img_size)  # Resize to uniform shape\n            images.append(img)\n\n            # Load the mask\n            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Read the mask in grayscale\n            mask = cv2.resize(mask, img_size)  # Resize to uniform shape\n            masks.append(mask)\n    \n    return np.array(images), np.array(masks)\n\n# Load the images and masks\nimages, masks = load_images_and_masks(lake_folder, mask_folder, img_size)\n\n# Function to calculate intensity based on the blue channel and classify depth\ndef calculate_depth_intensity(image, mask):\n    # Apply the mask to the image (select only water regions)\n    water_region = cv2.bitwise_and(image, image, mask=mask)\n    \n    # Extract the blue channel (index 0 in BGR images)\n    blue_channel = water_region[:, :, 0]\n\n    # Calculate the average intensity of the blue channel for the water region\n    blue_intensity = np.mean(blue_channel)  # Average across the height and width of the image\n\n    # Normalize the blue intensity (between 0 and 255)\n    blue_intensity_normalized = blue_intensity / 255.0\n\n    # Classify depth as Low, Medium, or High based on blue intensity\n    # Here, darker blue (lower values) correspond to higher depth\n    if blue_intensity_normalized < 0.33:\n        return 'High Depth', blue_intensity\n    elif blue_intensity_normalized < 0.66:\n        return 'Medium Depth', blue_intensity\n    else:\n        return 'Low Depth', blue_intensity\n\n# Loop through all images and calculate the depth intensity\ndepth_labels = []\ndepth_values = []\n\nfor img, mask in zip(images, masks):\n    label, depth = calculate_depth_intensity(img, mask)\n    depth_labels.append(label)\n    depth_values.append(depth)\n\n# Display some of the results\nfor i in range(5):  # Show 5 random results\n    plt.imshow(images[i])\n    plt.title(f\"Depth: {depth_labels[i]} - Blue Intensity: {depth_values[i]}\")\n    plt.axis('off')\n    plt.show()\n\nprint(\"âœ… Depth calculation and classification completed!\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-28T00:29:07.193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Function to load images and masks\ndef load_images_and_masks(lake_folder, mask_folder, img_size):\n    images = []\n    masks = []\n    \n    for filename in os.listdir(lake_folder):\n        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n            img_path = os.path.join(lake_folder, filename)\n            mask_path = os.path.join(mask_folder, filename)\n\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, img_size)\n            images.append(img)\n\n            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n            mask = cv2.resize(mask, img_size)\n            masks.append(mask)\n    \n    return np.array(images), np.array(masks)\n\n# Paths\nlake_folder = '/kaggle/working/harbor_data'\nmask_folder = '/kaggle/working/generated_masks'\nimg_size = (128, 128)\n\n# Load data\nimages, masks = load_images_and_masks(lake_folder, mask_folder, img_size)\n\n# Depth calculation\ndef calculate_depth_intensity(image, mask):\n    water_region = cv2.bitwise_and(image, image, mask=mask)\n    blue_channel = water_region[:, :, 0]\n    blue_intensity = np.mean(blue_channel)\n    blue_intensity_normalized = blue_intensity / 255.0\n\n    if blue_intensity_normalized < 0.33:\n        return 'High Depth', blue_intensity\n    elif blue_intensity_normalized < 0.66:\n        return 'Medium Depth', blue_intensity\n    else:\n        return 'Low Depth', blue_intensity\n\n# Label preparation\ndepth_labels = []\nfor img, mask in zip(images, masks):\n    label, _ = calculate_depth_intensity(img, mask)\n    depth_labels.append(label)\n\nlabel_map = {'Low Depth': 0, 'Medium Depth': 1, 'High Depth': 2}\ny = np.array([label_map[label] for label in depth_labels])\n\n# Introduce small noise: only 3% wrong labels\nnp.random.seed(42)\nnum_wrong_labels = int(len(y) * 0.03)  # 3% mislabel\nwrong_indices = np.random.choice(len(y), num_wrong_labels, replace=False)\nfor idx in wrong_indices:\n    y[idx] = np.random.choice([0, 1, 2])\n\n# Encode labels\ny_categorical = to_categorical(y, num_classes=3)\n\n# Normalize images\nX = images / 255.0\n\n# Train/test split\nX_train, X_val, y_train, y_val = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n\n# Model with slight Dropout\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3), kernel_regularizer=l2(0.001)),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=(2, 2)),\n\n    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.2),  # One small dropout here\n\n    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=(2, 2)),\n\n    Flatten(),\n    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n    Dropout(0.25),  # One more small dropout here\n    Dense(3, activation='softmax')\n])\n\n# Compile\noptimizer = Adam(learning_rate=0.0005)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Early stopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train\nhistory = model.fit(\n    X_train, y_train,\n    epochs=50,\n    batch_size=16,\n    validation_data=(X_val, y_val),\n    callbacks=[early_stopping]\n)\n\n# Plot\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# Save\nmodel.save('Corrected_CNN_LAKE.h5')\nprint(\"âœ… Model training done!\")\n\n# âž¡ï¸ Final Accuracy Printout\nfinal_train_acc = history.history['accuracy'][-1] * 100\nfinal_val_acc = history.history['val_accuracy'][-1] * 100\n\nprint(f\"ðŸŽ¯ Final Training Accuracy: {final_train_acc:.2f}%\")\nprint(f\"ðŸŽ¯ Final Validation Accuracy: {final_val_acc:.2f}%\")\nprint(\"âœ… Model saved as 'Corrected_CNN_LAKE.h5'\")\n\n# After training your model\nmodel.save('harbor_prediction.keras')\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-28T00:29:07.193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Add, Cropping2D\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\n\n# Load images and masks as before\ndef load_images_and_masks(lake_folder, mask_folder, img_size):\n    images = []\n    masks = []\n    for filename in os.listdir(lake_folder):\n        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n            img_path = os.path.join(lake_folder, filename)\n            mask_path = os.path.join(mask_folder, filename)\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, img_size)\n            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n            mask = cv2.resize(mask, img_size)\n            images.append(img)\n            masks.append(mask)\n    return np.array(images), np.array(masks)\n\n# Setup\nlake_folder = '/kaggle/working/harbor_data'\nmask_folder = '/kaggle/working/generated_masks'\nimg_size = (128, 128)\nimages, masks = load_images_and_masks(lake_folder, mask_folder, img_size)\n\n# Normalize\nX = images / 255.0\nmasks = masks / 255.0\nmasks = masks[..., np.newaxis]  # Add channel dimension\n\n# Split\nX_train, X_val, y_train, y_val = train_test_split(X, masks, test_size=0.2, random_state=42)\n\n# Build FCN model\ndef build_fcn_model(input_shape):\n    inputs = Input(shape=input_shape)\n    \n    # Encoder\n    x1 = Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n    p1 = MaxPooling2D((2,2))(x1)\n    \n    x2 = Conv2D(64, (3,3), activation='relu', padding='same')(p1)\n    p2 = MaxPooling2D((2,2))(x2)\n\n    x3 = Conv2D(128, (3,3), activation='relu', padding='same')(p2)\n\n    # Decoder\n    u1 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(x3)\n    m1 = Add()([u1, x2])\n    \n    u2 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(m1)\n    m2 = Add()([u2, x1])\n\n    outputs = Conv2D(1, (1,1), activation='sigmoid', padding='same')(m2)\n\n    model = Model(inputs, outputs)\n    return model\n\nmodel = build_fcn_model((128, 128, 3))\nmodel.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=16)\n\n# Save model\nmodel.save('FCN_LAKE_SEGMENTATION.h5')\n\n\n# Plot training and validation accuracy\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# Show final validation accuracy\nfinal_val_acc = history.history['val_accuracy'][-1] * 100\nprint(f\"âœ… Model training complete. Final Validation Accuracy: {final_val_acc:.2f}%\")\nprint(\"âœ… Model saved as 'FCN_LAKE_SEGMENTATION.h5'\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-28T00:29:07.193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\n\n# Load images and masks\ndef load_images_and_masks(lake_folder, mask_folder, img_size):\n    images = []\n    masks = []\n    for filename in os.listdir(lake_folder):\n        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n            img_path = os.path.join(lake_folder, filename)\n            mask_path = os.path.join(mask_folder, filename)\n\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, img_size)\n\n            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n            mask = cv2.resize(mask, img_size)\n\n            images.append(img)\n            masks.append(mask)\n    return np.array(images), np.array(masks)\n\nlake_folder = '/kaggle/working/harbor_data'\nmask_folder = '/kaggle/working/generated_masks'\nimg_size = (128, 128)\n\nimages, masks = load_images_and_masks(lake_folder, mask_folder, img_size)\n\n# Preprocess images: apply mask to keep water regions only\ndef apply_mask(img, mask):\n    return cv2.bitwise_and(img, img, mask=mask)\n\nmasked_images = [apply_mask(img, msk) for img, msk in zip(images, masks)]\n\n# Calculate depth label from average blue intensity\ndef calculate_depth_label(image):\n    blue_channel = image[:, :, 0]\n    mean_blue = np.mean(blue_channel)\n    norm = mean_blue / 255.0\n    if norm < 0.33:\n        return 2  # High Depth\n    elif norm < 0.66:\n        return 1  # Medium Depth\n    else:\n        return 0  # Low Depth\n\ndepth_labels = [calculate_depth_label(img) for img in masked_images]\ny = to_categorical(depth_labels, num_classes=3)\n\nX = np.array(masked_images) / 255.0\n\n# Train/test split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Load ResNet + GAP\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n\n# Freeze base layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Add classification head\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dense(128, activation='relu')(x)\noutput = Dense(3, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=output)\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=16)\n\n# Plot accuracy\nplt.plot(history.history['accuracy'], label='Train Acc')\nplt.plot(history.history['val_accuracy'], label='Val Acc')\nplt.title('ResNet + GAP Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# Save model\nmodel.save('RESNET_GAP_LAKE.h5')\nprint(\"âœ… Model saved as 'RESNET_GAP_LAKE.h5'\")\nfinal_val_acc = history.history['val_accuracy'][-1] * 100\nprint(f\"âœ… Model training complete. Final Validation Accuracy: {final_val_acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-28T00:29:07.193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}