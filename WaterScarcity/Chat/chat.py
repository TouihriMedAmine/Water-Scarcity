from langchain_ollama import OllamaLLM as Ollama
from langchain_community.vectorstores import FAISS
from langchain_ollama import OllamaEmbeddings
from langdetect import detect
from langdetect.lang_detect_exception import LangDetectException

# Load embeddings and vectorstore
embeddings = OllamaEmbeddings(model="mistral")
vectorstore = FAISS.load_local("vectorstore/", embeddings, allow_dangerous_deserialization=True)
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# Initialize LLM
llm = Ollama(
    model="mistral",
    temperature=0.7,
    top_p=0.9,
    top_k=50
)


def get_response(user_query):
    print("--- D√©but de la fonction get_response ---")
    print(f"Requ√™te utilisateur re√ßue : '{user_query}'")

    if not user_query.strip():
        print("La requ√™te utilisateur est vide ou ne contient que des espaces.")
        print("--- Fin de la fonction get_response (requ√™te vide) ---")
        return "Please enter a valid question."

    print("D√©tection de la langue...")
    try:
        language = detect(user_query)
        print(f"Langue d√©tect√©e : {language}")
    except LangDetectException:
        language = "en"  # default to English if detection fails
        print("√âchec de la d√©tection de la langue, utilisation de l'anglais par d√©faut.")

    print("R√©cup√©ration des documents pertinents (contexte)...")
    context = retriever.invoke(user_query)
    context_text = "\n".join([doc.page_content for doc in context])
    print(f"Contexte r√©cup√©r√© : \n---\n{context_text}\n---")

    print("Cr√©ation des instructions pour le persona...")
    if language == "fr":
        persona_instructions = """
You are "Droplets", an AI expert in water scarcity. You speak clearly, concisely, and kindly‚Äîlike a friendly environmental scientist. Stay focused only on water-related topics: water access, droughts, agriculture, climate impacts, clean water, sanitation, and resource management.

Politely decline off-topic questions and encourage rephrasing.

Behavior Guide:

Greet warmly but briefly.

Thank kindly if the user thanks you.

If facts come from documents, mention it humbly.

Use documents and history to inform responses.

Never make up facts. If unsure, say so clearly.

Maximum response: 60 words.
"""
        print("Instructions du persona en fran√ßais s√©lectionn√©es.")
    else:
        persona_instructions = """
YYou are "Droplets", an AI expert in water scarcity. You speak clearly, concisely, and kindly‚Äîlike a friendly environmental scientist. Stay focused only on water-related topics: water access, droughts, agriculture, climate impacts, clean water, sanitation, and resource management.

Politely decline off-topic questions and encourage rephrasing.

Behavior Guide:

Greet warmly but briefly.

Thank kindly if the user thanks you.

If facts come from documents, mention it humbly.

Use documents and history to inform responses.

Never make up facts. If unsure, say so clearly.

Maximum response: 60 words.
"""
        print("Instructions du persona en anglais s√©lectionn√©es.")

    print("Construction du prompt final...")
    prompt = f"""
{persona_instructions}

Use the following context to answer the user's question:

--- 
üìö Context: 
{context_text}
---
‚ùìUser Question: 
{user_query}
---
Your Response:
"""
    print(f"Prompt final construit : \n---\n{prompt}\n---")

    print("Invocation du mod√®le LLM...")
    # Note : Vous appelez llm.invoke deux fois. Pour l'efficacit√© et la coh√©rence,
    # il est pr√©f√©rable de l'appeler une seule fois et de stocker le r√©sultat.
    response_text = llm.invoke(prompt).strip()
    print(f"R√©ponse brute du LLM : '{response_text}'")
    
    print("--- Fin de la fonction get_response ---")
    return response_text

# Basic CLI
def chat():
    print("\nüåä Droplets Chatbot - Type 'exit' to quit.")
    while True:
        try:
            user_input = input("\nYou: ")
            if user_input.lower().strip() == "exit":
                print("üëã Goodbye! Stay curious about the water Scarcity.")
                break
            response = get_response(user_input)
            print("Bot:", response)
        except KeyboardInterrupt:
            print("\nüëã Goodbye! Stay curious about the water scarcity.")
            break
